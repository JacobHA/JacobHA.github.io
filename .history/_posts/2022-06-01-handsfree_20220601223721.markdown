---
layout: post
title:  "HandsFree: Manipulating 3D Files by Hand Gestures"
date:   2022-06-01 22:30:57 -0400
categories: projects
---

I have been working (on and off for the past year) on interfacing with 3D objects (files like *.stl, *.obj, etc.) through hand gestures. I realize the name for the project is a bit ironic! The purpose is to use your hands in "real life" rather than through the mouse to manipulate 3D objects in a more "natural" way.

I think this project was unconsciously inspired by a video released some time ago by [SpaceX][spacex-video]. However, their demo involves the use of some extra add-on motion sensors. I want to enable the same interactivity with the bare bones: a simple built-in laptop camera. This makes the problem substantially more difficult, because with just a camera we can only see a 2D representation of the scene (our hands). (This can be slightly bypassed by more advanced pose estimation, and with using infrared sensors, included on some laptops - but I want to keep it as basic as possible so that there are no hardware limitations.)

There are several simple features:
- Zooming: think pinch to zoom
- Rotating: not very intuitive with 2D representation
- Panning: think of dragging hands across the screen

There should also be other simple poses which allow for:
- Pausing: so the image is locked in place
- Resetting: so the image goes back to its original position


Currently, I use the thumb and forefinger to define an axis of rotation, and the distance between fingers defines the rotation rate. 
I highly request suggestions on alternate ways of defining rotation (which are intuitive to use)!

Please file all bugs/feature requests at [this repository][handsfree-repo].

<script data-href="https://github.com/JacobHA/HandsFree" data-target = "_blank" src="https://unpkg.com/github-corners@0.1.0/dist/embed.min.js"></script>


[spacex-video]: https://www.youtube.com/watch?v=xNqs_S-zEBY
[handsfree-repo]: https://github.com/JacobHA/HandsFree
